# Introduction

## What is Machine Learning?

* there are two definitions
  * Arthur Samuel
    "the field study that gives computers the ability to learn without beinge explicitly programmed" this is an older, informal definition.
  * Tom Mitchell
    " A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E"
    * example
      * E = the experience of playing many games of checkers.
      * T = the tasks of playing checkers.
      * P = the probability that the program will win the next gamke.

## Supervised Learning

In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.

In supervised learning, there is a data set that have answers. the program leared from those data and answers, and then it can predict an answer from a datum.

There are two types of supervised learning problems, one is "regression" and the other is "classification".
In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function.

In a classification problem, we are trying to predict results in a discrete output. we are trying to map input variables into discrete categories.

memo:
ML can handle infinite features like cell size, clump thickness, uniformity cell size, uniformity cell numbers, etc...
then, how ML handle those inifinite attributes/features?
Like SVM, mathmatical techniques makes this available

### Example about regression and classification problems

* (a): Regression: Given a house place distance from a station, we have to predict their prices on the basis of the given distance
* (b): Classification: Given a patient with a tumor, we have to predict whethere the tumor is malignant or benign.

### terms

* malignan = 悪性
* benign = 良性
* tumor = 腫瘍
* descrete = 分散型の(離散型？)
* clump thickness = 塊の厚さ → 細胞が固まって厚みをもつ → 悪性腫瘍にありがちらしい
* uniformity = 均一性

## Unsupervised Learning

* Unsupervised learning allows us to approach problems with little or no idea what our results should look like.
* We can derive structure from data where we don't nessesarily know the effedct of the variables.
* We can derive this structur by clustering the data based on relationship among the variables in the data.
* With unsupervised learning there is no feedback based on the prediction results.

* Two diffrent microphones recorded two different voices/music. In this case, one recorded a voice which counting in English and another recorded a voice which counting in Spanish. And ML program find groups of voices and it separate voices into to two groups that are in English and in Spanish. So, the first output is in English and Spanish was removed.

* Microphone experiment program was coded in Octave. He said that Octave is helpful when it is used for making a prototype. It is faster to make a prototype because in Java/C++/Ptthon you need to link many libraries and need to write much more code than in Octave.

### memo

* Unsupervised learning can find some groups in data which is called clusttering.
* Clusttering: I might be able to classify EC customers into different cluster.
